{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import sklearn\n",
    "import pathlib as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment                                           sentence\n",
      "0   neutral  According to Gran , the company has no plans t...\n",
      "1   neutral  Technopolis plans to develop in stages an area...\n",
      "2  negative  The international electronic industry company ...\n",
      "3  positive  With the new production plant the company woul...\n",
      "4  positive  According to the company 's updated strategy f...\n",
      "5  positive  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...\n",
      "6  positive  For the last quarter of 2010 , Componenta 's n...\n",
      "7  positive  In the third quarter of 2010 , net sales incre...\n",
      "8  positive  Operating profit rose to EUR 13.1 mn from EUR ...\n",
      "9  positive  Operating profit totalled EUR 21.1 mn , up fro...\n"
     ]
    }
   ],
   "source": [
    "path = '../dataset/finRep/FinancialPhraseBank/all-data.csv'\n",
    "df = pd.read_csv(path, encoding = \"ISO-8859-1\", names = ['sentiment', 'sentence'])\n",
    "print(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install keybert\n",
    "# !pip install nltk\n",
    "# !pip install keybert\n",
    "# !pip install sentence-transformers\n",
    "# !pip install git+https://github.com/LIAAD/yake\n",
    "### To show the execution times\n",
    "# !pip install ipython-autotime\n",
    "# %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`` Because we 're a pension insurance company , we 're required to diversify and not put too much in one asset class .\n",
      "the sentiment is : negative\n"
     ]
    }
   ],
   "source": [
    "# choose a random sample\n",
    "text = df.sample(1)['sentence'].iloc[0]\n",
    "label = df.sample(1)['sentiment'].iloc[0]\n",
    "print(text)\n",
    "print(\"the sentiment is : %s\"%label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "rake_nltk_var = Rake()\n",
    "\n",
    "rake_nltk_var.extract_keywords_from_text(text)\n",
    "keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "print(keyword_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import them\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sent_trans = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "keyBERT_model = KeyBERT(model = sent_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terms(document, n_gram_range = (3,3), \n",
    "                  top_N=5, model=keyBERT_model, diversity_threshold = 0.7):\n",
    "\n",
    "  keywords = model.extract_keywords(document, stop_words='english', \n",
    "                                    keyphrase_ngram_range=(1, 3),\n",
    "                                    use_mmr=True, \n",
    "                                    diversity = diversity_threshold,\n",
    "                                    top_n = top_N)\n",
    "  \n",
    "  return sorted(keywords, key=lambda tup:(-tup[1], tup[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The Marubeni Group focuses on creating `` value chain '' from upstream to downstream , encompassing a wide variety of business fields , including oil & gas , metals , mineral resources , foods , pulp & paper and chemicals , among others ..\n",
      "Length: 44\n",
      "('value chain upstream', 0.7109)\n",
      "('marubeni', 0.4173)\n",
      "('resources foods pulp', 0.2288)\n",
      "('encompassing wide variety', 0.2081)\n",
      "('gas metals', 0.1838)\n"
     ]
    }
   ],
   "source": [
    "print(f'Text: {text}.\\nLength: {len(text.split())}')\n",
    "best_terms = extract_terms(text)\n",
    "\n",
    "for terms_and_score in best_terms:\n",
    "  print(terms_and_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "\n",
    "for kw in keywords:\n",
    "\tprint(kw)\n",
    "\n",
    "\n",
    "print(\"SECOND FORM:\")\n",
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_threshold = 0.9\n",
    "deduplication_algo = 'seqm'\n",
    "windowSize = 1\n",
    "numOfKeywords = 20\n",
    "\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, dedupFunc=deduplication_algo, windowsSize=windowSize, top=numOfKeywords, features=None)\n",
    "keywords = custom_kw_extractor.extract_keywords(text)\n",
    "\n",
    "for kw in keywords:\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK-VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive : ['great']\n",
      "Neutral : ['20170412', 'terrible', 'dog', 'stop', 'good', 'prices', 'increasing']\n",
      "Negative : ['bad']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "test_subset=['20170412', 'great', 'bad', 'terrible', 'dog', 'stop', 'good','prices','increasing']\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "pos_word_list=[]\n",
    "neu_word_list=[]\n",
    "neg_word_list=[]\n",
    "\n",
    "for word in test_subset:\n",
    "    if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "        pos_word_list.append(word)\n",
    "    elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "        neg_word_list.append(word)\n",
    "    else:\n",
    "        neu_word_list.append(word)                \n",
    "\n",
    "print('Positive :',pos_word_list)        \n",
    "print('Neutral :',neu_word_list)    \n",
    "print('Negative :',neg_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive : ['great', 'good']\n",
      "Neutral : ['20170412', 'prices', 'increasing', 'fat']\n",
      "Negative : ['bad', 'terrible', 'bad']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def word_polarity(test_subset):\n",
    "    pos_word_list=[]\n",
    "    neu_word_list=[]\n",
    "    neg_word_list=[]\n",
    "\n",
    "    for word in test_subset:               \n",
    "        testimonial = TextBlob(word)\n",
    "        if testimonial.sentiment.polarity >= 0.5:\n",
    "            pos_word_list.append(word)\n",
    "        elif testimonial.sentiment.polarity <= -0.5:\n",
    "            neg_word_list.append(word)\n",
    "        else:\n",
    "            neu_word_list.append(word)\n",
    "\n",
    "    print('Positive :',pos_word_list)        \n",
    "    print('Neutral :',neu_word_list)    \n",
    "    print('Negative :',neg_word_list)      \n",
    "\n",
    "word_polarity(['20170412', 'great', 'bad', 'terrible', 'prices', 'increasing', 'good','bad','fat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
