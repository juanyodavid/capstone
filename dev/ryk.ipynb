{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import sklearn\n",
    "import pathlib as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionarypath = '../dataset/dictionary/Loughran-McDonald_MasterDictionary_1993-2021.csv'\n",
    "wds_dict = pd.read_csv(dictionarypath)\n",
    "positive_wds = [row['Word'].lower() for i, row in wds_dict.iterrows() if row['Positive']!=0]\n",
    "negative_wds = [row['Word'].lower() for i, row in wds_dict.iterrows() if row['Negative']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dataset/finRep/FinancialPhraseBank/all-data.csv'\n",
    "df = pd.read_csv(path, encoding = \"ISO-8859-1\", names = ['sentiment', 'sentence'])\n",
    "# print(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install keybert\n",
    "# !pip install nltk\n",
    "# !pip install keybert\n",
    "# !pip install sentence-transformers\n",
    "# !pip install git+https://github.com/LIAAD/yake\n",
    "### To show the execution times\n",
    "# !pip install ipython-autotime\n",
    "# %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will also strengthen Ruukki 's offshore business .\n",
      "the sentiment is : positive\n"
     ]
    }
   ],
   "source": [
    "# choose a random sample\n",
    "text = df.sample(1)['sentence'].iloc[0]\n",
    "label = df.sample(1)['sentiment'].iloc[0]\n",
    "print(text)\n",
    "print(\"the sentiment is : %s\"%label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_keyword_list(keyword_list):\n",
    "    keys = []\n",
    "    for keyword in keyword_list:\n",
    "        keys.append(keyword[0])\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also strengthen ruukki', 'offshore business']\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "rake_nltk_var = Rake()\n",
    "\n",
    "rake_nltk_var.extract_keywords_from_text(text)\n",
    "keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "print(keyword_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import them\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sent_trans = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "keyBERT_model = KeyBERT(model = sent_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terms(document, n_gram_range = (3,3), \n",
    "                  top_N=5, model=keyBERT_model, diversity_threshold = 0.7):\n",
    "\n",
    "  keywords = model.extract_keywords(document, stop_words='english', \n",
    "                                    keyphrase_ngram_range=(1, 3),\n",
    "                                    use_mmr=True, \n",
    "                                    diversity = diversity_threshold,\n",
    "                                    top_n = top_N)\n",
    "  \n",
    "  return sorted(keywords, key=lambda tup:(-tup[1], tup[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: It will also strengthen Ruukki 's offshore business ..\n",
      "Length: 9\n",
      "['ruukki offshore business', 'strengthen ruukki', 'offshore', 'strengthen', 'business']\n"
     ]
    }
   ],
   "source": [
    "print(f'Text: {text}.\\nLength: {len(text.split())}')\n",
    "best_terms = extract_terms(text)\n",
    "best_terms = normalize_keyword_list(best_terms)\n",
    "\n",
    "print(best_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['strengthen Ruukki', 'offshore business', 'Ruukki', 'business', 'strengthen', 'offshore']\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "keywords = normalize_keyword_list(keywords)\n",
    "\n",
    "print(keywords)\n",
    "\n",
    "\n",
    "# print(\"SECOND FORM:\")\n",
    "# language = \"en\"\n",
    "# max_ngram_size = 3\n",
    "# deduplication_threshold = 0.9\n",
    "# deduplication_algo = 'seqm'\n",
    "# windowSize = 1\n",
    "# numOfKeywords = 20\n",
    "\n",
    "# custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, dedupFunc=deduplication_algo, windowsSize=windowSize, top=numOfKeywords, features=None)\n",
    "# keywords = custom_kw_extractor.extract_keywords(text)\n",
    "\n",
    "# for kw in keywords:\n",
    "#     print(kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK-VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ruukki offshore business', 'strengthen ruukki', 'offshore', 'strengthen', 'business']\n"
     ]
    }
   ],
   "source": [
    "print(best_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('ruukki', 0), ('offshore', 0), ('business', 0)], [('strengthen', 0), ('ruukki', 0)], [('offshore', 0)], [('strengthen', 0)], [('business', 0)]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "result = []\n",
    "for sentence in best_terms:\n",
    "    s = sentence.split()\n",
    "    keyword_sen = []\n",
    "    for word in s:\n",
    "        if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "            keyword_sen.append(tuple((word, 1)))\n",
    "        elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "            keyword_sen.append(tuple((word, -1)))\n",
    "        else:\n",
    "            keyword_sen.append(tuple((word, 0)))\n",
    "    result.append(keyword_sen)\n",
    "\n",
    "print(result)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('ruukki', 0), ('offshore', 0), ('business', 0)], [('strengthen', 0), ('ruukki', 0)], [('offshore', 0)], [('strengthen', 0)], [('business', 0)]]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "result = []\n",
    "for sentence in best_terms:\n",
    "    s = sentence.split()\n",
    "    keyword_sen = []\n",
    "    for word in s:\n",
    "        testimonial = TextBlob(word)\n",
    "        if testimonial.sentiment.polarity >= 0.5:\n",
    "            keyword_sen.append(tuple((word, 1)))\n",
    "        elif testimonial.sentiment.polarity <= -0.5:\n",
    "            keyword_sen.append(tuple((word, -1)))\n",
    "        else:\n",
    "            keyword_sen.append(tuple((word, 0)))\n",
    "    result.append(keyword_sen)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_words(keyword_list):\n",
    "    result = []\n",
    "    for sentence in keyword_list:\n",
    "        words = sentence.split()\n",
    "        keyword_sen = []\n",
    "        for word in words:\n",
    "            if word in positive_wds:\n",
    "                keyword_sen.append(tuple((word, 1)))\n",
    "            elif word in negative_wds:\n",
    "                keyword_sen.append(tuple((word, -1)))\n",
    "            else:\n",
    "                keyword_sen.append(tuple((word, 0)))\n",
    "        result.append(keyword_sen)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('ruukki', 0), ('offshore', 0), ('business', 0)], [('strengthen', 1), ('ruukki', 0)], [('offshore', 0)], [('strengthen', 1)], [('business', 0)]]\n"
     ]
    }
   ],
   "source": [
    "keybert_sen = compare_words(best_terms) #keybert\n",
    "\n",
    "print(keybert_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Using cached flair-0.11.3-py3-none-any.whl (401 kB)\n",
      "Collecting conllu>=4.0\n",
      "  Using cached conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (2022.9.13)\n",
      "Collecting janome\n",
      "  Using cached Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (1.0.2)\n",
      "Requirement already satisfied: segtok>=1.5.7 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (1.5.11)\n",
      "Collecting gdown==4.4.0\n",
      "  Using cached gdown-4.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (0.10.0)\n",
      "Collecting wikipedia-api\n",
      "  Using cached Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting matplotlib>=2.2.3\n",
      "  Using cached matplotlib-3.5.3-cp37-cp37m-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (2.0.0)\n",
      "Collecting mpld3==0.3\n",
      "  Using cached mpld3-0.3.tar.gz (788 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from flair) (2.8.2)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Using cached Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pptree\n",
      "  Using cached pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tabulate in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (0.9.0)\n",
      "Requirement already satisfied: transformers>=4.0.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (4.22.2)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting hyperopt>=0.2.7\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting ftfy\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Using cached konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Collecting gensim>=3.4.0\n",
      "  Using cached gensim-4.2.0-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.9.1-cp37-cp37m-win_amd64.whl (3.6 MB)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Using cached bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (1.12.1)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (0.1.95)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (4.64.1)\n",
      "Collecting more-itertools\n",
      "  Using cached more_itertools-8.14.0-py3-none-any.whl (52 kB)\n",
      "Requirement already satisfied: six in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from gdown==4.4.0->flair) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown==4.4.0->flair) (3.8.0)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown==4.4.0->flair) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Using cached wrapt-1.14.1-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim>=3.4.0->flair) (1.7.3)\n",
      "Collecting Cython==0.29.28\n",
      "  Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting py4j\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Using cached importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Using cached overrides-3.1.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp37-cp37m-win_amd64.whl (54 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib>=2.2.3->flair) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.37.4-py3-none-any.whl (960 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib>=2.2.3->flair) (9.2.0)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.26.0->flair) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers>=4.0.0->flair) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers>=4.0.0->flair) (0.12.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (2.1.1)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using legacy 'setup.py install' for mpld3, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for langdetect, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pptree, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wikipedia-api, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for overrides, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for future, since package 'wheel' is not installed.\n",
      "Installing collected packages: py4j, pptree, overrides, mpld3, janome, wrapt, soupsieve, PySocks, more-itertools, lxml, langdetect, kiwisolver, importlib-metadata, future, ftfy, fonttools, Cython, cycler, conllu, cloudpickle, wikipedia-api, matplotlib, konoha, hyperopt, gensim, deprecated, beautifulsoup4, gdown, bpemb, flair\n",
      "  Running setup.py install for pptree: started\n",
      "  Running setup.py install for pptree: finished with status 'done'\n",
      "  Running setup.py install for overrides: started\n",
      "  Running setup.py install for overrides: finished with status 'done'\n",
      "  Running setup.py install for mpld3: started\n",
      "  Running setup.py install for mpld3: finished with status 'done'\n",
      "  Running setup.py install for langdetect: started\n",
      "  Running setup.py install for langdetect: finished with status 'done'\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.0.0\n",
      "    Uninstalling importlib-metadata-5.0.0:\n",
      "      Successfully uninstalled importlib-metadata-5.0.0\n",
      "  Running setup.py install for future: started\n",
      "  Running setup.py install for future: finished with status 'done'\n",
      "  Running setup.py install for wikipedia-api: started\n",
      "  Running setup.py install for wikipedia-api: finished with status 'done'\n",
      "Successfully installed Cython-0.29.28 PySocks-1.7.1 beautifulsoup4-4.11.1 bpemb-0.3.4 cloudpickle-2.2.0 conllu-4.5.2 cycler-0.11.0 deprecated-1.2.13 flair-0.11.3 fonttools-4.37.4 ftfy-6.1.1 future-0.18.2 gdown-4.4.0 gensim-4.2.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 kiwisolver-1.4.4 konoha-4.6.5 langdetect-1.0.9 lxml-4.9.1 matplotlib-3.5.3 more-itertools-8.14.0 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.7 soupsieve-2.3.2.post1 wikipedia-api-0.5.4 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Using cached flair-0.11.3-py3-none-any.whl (401 kB)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Using cached konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: janome in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (0.4.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (0.9.0)\n",
      "Requirement already satisfied: transformers>=4.0.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (4.22.2)\n",
      "Collecting matplotlib>=2.2.3\n",
      "  Using cached matplotlib-3.5.3-cp37-cp37m-win_amd64.whl (7.2 MB)\n",
      "Collecting gensim>=3.4.0\n",
      "  Using cached gensim-4.2.0-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (0.10.0)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Using cached bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (4.64.1)\n",
      "Requirement already satisfied: mpld3==0.3 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (0.3)\n",
      "Collecting ftfy\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting conllu>=4.0\n",
      "  Using cached conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (1.0.2)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.9.1-cp37-cp37m-win_amd64.whl (3.6 MB)\n",
      "Collecting more-itertools\n",
      "  Using cached more_itertools-8.14.0-py3-none-any.whl (52 kB)\n",
      "Collecting hyperopt>=0.2.7\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: segtok>=1.5.7 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (1.5.11)\n",
      "Collecting gdown==4.4.0\n",
      "  Using cached gdown-4.4.0-py3-none-any.whl\n",
      "Collecting wikipedia-api\n",
      "  Using cached Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (2.0.0)\n",
      "Requirement already satisfied: regex in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (2022.9.13)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from flair) (2.8.2)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Using cached Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (0.1.95)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (1.12.1)\n",
      "Requirement already satisfied: pptree in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from flair) (3.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown==4.4.0->flair) (2.28.1)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown==4.4.0->flair) (3.8.0)\n",
      "Requirement already satisfied: six in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from gdown==4.4.0->flair) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Using cached wrapt-1.14.1-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim>=3.4.0->flair) (1.7.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
      "Collecting Cython==0.29.28\n",
      "  Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: py4j in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
      "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Using cached importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib>=2.2.3->flair) (9.2.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.37.4-py3-none-any.whl (960 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib>=2.2.3->flair) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp37-cp37m-win_amd64.whl (54 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.26.0->flair) (0.4.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers>=4.0.0->flair) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers>=4.0.0->flair) (6.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\rolando\\appdata\\roaming\\python\\python37\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (1.26.12)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using legacy 'setup.py install' for langdetect, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wikipedia-api, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for future, since package 'wheel' is not installed.\n",
      "Installing collected packages: wrapt, soupsieve, PySocks, more-itertools, lxml, langdetect, kiwisolver, importlib-metadata, future, ftfy, fonttools, Cython, cycler, conllu, cloudpickle, wikipedia-api, matplotlib, konoha, hyperopt, gensim, deprecated, beautifulsoup4, gdown, bpemb, flair\n",
      "  Running setup.py install for langdetect: started\n",
      "  Running setup.py install for langdetect: finished with status 'done'\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.0.0\n",
      "    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n",
      "  Running setup.py install for future: started\n",
      "  Running setup.py install for future: finished with status 'done'\n",
      "  Running setup.py install for wikipedia-api: started\n",
      "  Running setup.py install for wikipedia-api: finished with status 'done'\n",
      "Successfully installed Cython-0.29.28 PySocks-1.7.1 beautifulsoup4-4.11.1 bpemb-0.3.4 cloudpickle-2.2.0 conllu-4.5.2 cycler-0.11.0 deprecated-1.2.13 flair-0.11.3 fonttools-4.37.4 ftfy-6.1.1 future-0.18.2 gdown-4.4.0 gensim-4.2.0 hyperopt-0.2.7 importlib-metadata-3.10.1 kiwisolver-1.4.4 konoha-4.6.5 langdetect-1.0.9 lxml-4.9.1 matplotlib-3.5.3 more-itertools-8.14.0 soupsieve-2.3.2.post1 wikipedia-api-0.5.4 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for importlib-metadata: [Errno 2] No such file or directory: 'c:\\\\users\\\\rolando\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\importlib_metadata-5.0.0.dist-info\\\\METADATA'\n",
      "    WARNING: No metadata found in c:\\users\\rolando\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-16 18:49:44,443 loading file C:\\Users\\Rolando\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n",
      "[[(Sentence: \"ruukki\" → NEGATIVE (0.9388), 1), (Sentence: \"offshore\" → POSITIVE (0.9857), 1), (Sentence: \"business\" → POSITIVE (0.9777), 1)], [(Sentence: \"strengthen\" → POSITIVE (0.9987), 1), (Sentence: \"ruukki\" → NEGATIVE (0.9388), 1)], [(Sentence: \"offshore\" → POSITIVE (0.9857), 1)], [(Sentence: \"strengthen\" → POSITIVE (0.9987), 1)], [(Sentence: \"business\" → POSITIVE (0.9777), 1)]]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "result = []\n",
    "for sentence in best_terms:\n",
    "    s = sentence.split()\n",
    "    keyword_sen = []\n",
    "    for word in s:\n",
    "        word = Sentence(word)\n",
    "        classifier.predict(word)\n",
    "        if (word.labels[0].score) >= 0.5:\n",
    "            keyword_sen.append(tuple((word, 1)))\n",
    "        elif (word.labels[0].score) <= -0.5:\n",
    "            keyword_sen.append(tuple((word, -1)))\n",
    "        else:\n",
    "            keyword_sen.append(tuple((word, 0)))\n",
    "    result.append(keyword_sen)\n",
    "\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78523145c45833d40afbe49950902184139bffe318f4eab827c9aacbfef7acc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
